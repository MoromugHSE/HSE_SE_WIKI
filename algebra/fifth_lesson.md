---
title: 05. Ранг матриц
description: 
published: 1
date: 2020-11-17T22:37:57.205Z
tags: 
editor: markdown
dateCreated: 2020-10-07T14:12:01.086Z
---

## Свойства обратной матрицы
1. $(A\cdot B)^{-1} = B^{-1} \cdot A^{-1} \space$
2. $(A^T)^{-1} = (A^{-1})^T$
$$
\square ~ (A\cdot B) \cdot B^{-1} \cdot A^{-1} = A(B\cdot B^{-1}) \cdot A^{-1} = A \cdot A^{-1} = E \\
B^{-1} \cdot A^{-1} \cdot (A\cdot B) = B^{-1} \cdot (A^{-1} \cdot A) \cdot B = B^{-1} \cdot B = E ~ \blacksquare
$$

## Вычисление обратной матрицы
I. С помощью союзной матрицы по формуле: 
$$
A^{-1} = \frac{1}{\det A} \cdot \widetilde{A} \\
n = 2,3
$$
II. Элементарные преобразования. Обратная матрица удовлетворяет уравнению
$$
A_{n*n}\cdot X_{n*n} = E_{n*n} \\
$$
Если разрежем $X$ и $E$ на столбцы, то можно решать $n$ СЛАУ $A\cdot x = e_i$ 

Способ: по матрице $A$ составить матрицу $(A|E)_{n*2n}$ b и привести ее к каноническому виду. Если $A$-невырожденная матрица, то $\thicksim (E|B)$. Матрица $B$ и будет $A^{-1}\space$

**Утверждение** Если обратная матрица существует - то она единственна
$$
\square \text{Пусть } B \text{ и } B' \text{ - обратные к } A \\
\text{Тогда } B = B\cdot E = B\cdot (A\cdot B') = \\
= (B\cdot A) B' = E\cdot B' = B' \blacksquare
$$

**Определение**\
СЛАУ $A \cdot x = b$ называется **однородной**, если $b = 0$:\
\
**Следствие:**\
У однородной системы с квадратной невырожденной матрицей есть только 1 нулевое решение:\
$A \cdot x = 0 ~~~~~~~ | \cdot A^{-1}$ слева $\Longleftrightarrow x = 0$


# Ранг матрицы
Рассмотрим прямоугольную матрицу $A \in M_{mn}(\R)$

**Определение** Минором $k$-го порядка матрицы $A$ называют определитель матрицы, составленной из элементов, стоящих на пересечении произвольных $k$ строки и $k$ столбцов

Обозначение:
$$
M \begin{array}{c c c}
j_1 & \dots & j_k & & - \text{ номера столбцов } \\ 
i_1 & \dots & i_k & & - \text{ номера строк }	
\end{array}
$$

Пример
$$
A = \begin{pmatrix}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12 \\
\end{pmatrix}_{3*4} 
$$

$$
M_{12}^{23} = \begin{vmatrix}
2 & 3 \\
6 & 7
\end{vmatrix} = 14 - 18 = -4
$$

k - называется **порядком минора**

**Определение** 
*Рангом* матрицы называют наивысший порядок отличного от нуля минора

Обозначение $RgA$

Пример:
$$
A = \begin{pmatrix}
5 & 5 & 5 \\
\boxed{2} & 2 & 2
\end{pmatrix}, RgA = 1 \quad M_2^1 = 2 \not= 0
$$

Значит 
$Rg A \le min(m, n)$

**Определение** означает, что

1. 
$$
\exists M_{i_1\dots i_r}^{j_1\dots j_r} \not= 0
$$
(минор $r$-го порядка $r=RgA$)

2. Все миноры порядков $r+1, r+2, \dots$ равны нулю (или $\nexists$)

**Определение**
Любой, отличный от нуля минор матрицы, порядок которого равен рангу, называют **базисным минором** матрицы.
Столбцы (строки) попавшие в базисный минор называются базисными.

**Определение**
Линейной комбинацией строк $a_1,...,a_s$ одинаковой длины называют выражение вида:
$\alpha_1a_1 + ... + \alpha_sa_s = \sum_{k=1}^{s}~\alpha_ka_k~~~~$, где $\alpha_1,...,\alpha_s$ - некоторые числа

**Определение**
Строки $a_1,...,a_s$ называют **линейно зависимыми**, если $\exist$ числа $\alpha_1,...,\alpha_s$ не все равные 0, такие что $\alpha_1a_1 + ... + \alpha_sa_s = 0$

**Замечание**
Иногда говорят, что $a_1,...,a_s$ **линейно зависимы**, если существует нетривиальная (хотя бы 1 коэф. не 0) линейная комбинация равная 0 

**Определение**
Если равенство $\alpha_1a_1 + ... + \alpha_sa_s = 0$ возможно только при $\alpha_1 = \alpha_2 = ... = \alpha_s = 0$, то $a_1,...,a_s$ называются **линейно независимыми**




### Свойства ранга
1. $Rg A^T = Rg A$ 
$$
\square \text{Покажем, что } RgA^T \ge RgA \\
\text{Пусть } Rg A = r \implies \exists \text{ минор} \\
M_{i_1\dots i_r}^{j_1\dots j_r} \not= 0. \text{ В матрице } A^T \text{ есть минор } \\
N_{j_1\dots j_r}^{i_1\dots i_r} \text{ получающиеся из } M \text{ операцией транспонирования.} \\
\text{И } N\not= 0 \text{ по свойствам определителя (1 свойство)} \implies \\
\implies RgA^T \ge r = Rg A \\
Rg A \le Rg A^T \le Rg  (A^T)^T = Rg A \implies R A^T = Rg A \blacksquare
$$
2. Элемент преобразования преобразования строк не меняют ранга матрицы

## Методы нахождения ранга
1. Элементарные преобразования
    1. Методом Гаусса приводим к ступенчатому виду
    2. $RgA_{ступ} =$ число ненулевых строк
    3. $RgA = RgA_{ступ}$ по свойсву 2
2. Метод окаймляющих миноров

**Опредление** Минор $N$ - называют окоймляющим для минора $M$, если $N$ получается добавлением к $M$ одной новой строки и одного нового стобца матрицы $A$

**Утверждение** Пусть $A \in M_mn (\R)$ и 

1. существует минор $M$ порядка $r$, и он $\not= 0$
2. Все минору, окоймляющие $M$ равны $0$. Тогда $RgA = r$

## Линейная зависимость
**Определение** Линейной комбинацией строк (столбцов) $a_1,\dots,a_s$ одинаковой длины называют выражение вида:
$$
\alpha_1a_1 + \dots + \alpha_s a_s = \sum_{k=1}^{s} \alpha_k a_k \\
\alpha_1, \dots, \alpha_s \text{ - некоторые числа}
$$

> Обратите внимание на отличие между $\alpha$ и $a$

**Определение** Строки $a_1, \dots, a_s$ называют линейно зависимыми, если существуют числа $\alpha_1, \dots, \alpha_s$ не все равные $0$, такие что: $\alpha_1a_1 + \dots + \alpha_1 a_s = 0$

**Замечание** Говорят, что $a_1,\dots,a_s$ л.з., если существует нетривиальная (хотя бы 1 коэфициент $\not=0$) их линейная комбинация, равная 0

**Определение** Если равенство $\alpha_1a_1 + \dots + \alpha_1 a_s = 0$ возможно только в случае $\alpha_1 = \alpha_2 = \dots = \alpha_s = 0$, то $a_1, \dots, s_s$ называют линейно независимыми (л.н.з.)

**Утверждение** (критерий линейной зависимости)
$$
a_1, \dots, a_s - \text{ л.з. } \iff \text{хотя бы один из } a_1, \dots, a_s \text{ линейно выразится через остальные}
$$

$$
\square \textbf{Необходимость. } \\
\text{Дано: } a_1, \dots, a_s - \text{ л.з} \\
\text{Доказать: найдется выражаемая через другие линейно} \\
\text{По определению} \\
\exists \alpha_1, \dots, \alpha_s: \alpha_1\cdot a_1 + \dots + \alpha_s\cdot a_s = 0 \\
\text{Пусть } \alpha_1 \not= 0. \text{ Тогда } a_1 = -\frac{\alpha_1}{\alpha_1} - \dots -\frac{\alpha_s}{\alpha_1}a_s \\
\textbf{Достаточность}\\
\text{Дано: один выразится линейно через другие}  \\
\text{Доказать: при л.з.} \\
a_1 = \beta_2 a_2 + \dots + \beta_s a_s \\
1 \cdot a_1 - \beta_2 a_2 - \dots  - \beta_s a_s = 0 \\
\text{это нетривиальная линейная комбинация} \implies \text{по опредленеию они л.з.} \blacksquare
$$
